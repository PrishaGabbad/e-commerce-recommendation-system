# -*- coding: utf-8 -*-
"""e commerce recommendation system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tFLIPyHRjCC-4esuP_EvotlHa_OWW8jG
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

import os
from scipy.sparse import coo_matrix

from google.colab import files
uploaded = files.upload()

train_data = pd.read_csv('flipkart_com-ecommerce_sample.csv')
train_data.columns

train_data.head()

train_data = train_data[['uniq_id', 'product_url', 'product_name',
       'product_category_tree', 'retail_price', 'discounted_price',
       'image',  'description', 'product_rating',
       'overall_rating', 'brand', 'product_specifications']]

train_data.shape

train_data.isnull().sum()

train_data['uniq_id'] = train_data['uniq_id'].fillna(0)
train_data['brand'] = train_data['brand'].fillna('')
train_data['product_url'] = train_data['product_url'].fillna(0)
train_data['product_name'] = train_data['product_name'].fillna('')
train_data['product_category_tree'] = train_data['product_category_tree'].fillna('')
train_data['retail_price'] = train_data['retail_price'].fillna(0)
train_data['discounted_price'] = train_data['discounted_price'].fillna(0)
train_data['image'] = train_data['image'].fillna(0)
train_data['description'] = train_data['description'].fillna(0)
train_data['product_rating'] = train_data['product_rating'].fillna(0)
train_data['overall_rating'] = train_data['overall_rating'].fillna(0)
train_data['product_specifications'] = train_data['product_specifications'].fillna(0)

train_data.isnull().sum()

train_data

# Number of unique products
num_items = train_data['ID'].nunique()

# Number of unique rating values
num_ratings = train_data['Rating'].nunique()

print(f"Number of unique items: {num_items}")
print(f"Number of unique rating values: {num_ratings}")



# Replace text with NaN and convert ratings to numeric
train_data['overall_rating'] = pd.to_numeric(
    train_data['overall_rating'], errors='coerce'
)

# Drop rows with missing brand or rating
train_data = train_data.dropna(subset=['brand', 'overall_rating'])

heatmap_data = train_data.pivot_table(values='overall_rating', index='brand', aggfunc='mean')

plt.figure(figsize=(8, 10))
sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)
plt.title('Heatmap of Average Product Ratings by Brand')
plt.xlabel('Average Rating')
plt.ylabel('Brand')
plt.show()

popular_items = train_data['product_name'].value_counts().head(5)
popular_items.plot(kind='bar', color='red')
plt.title("Most Popular Products")
plt.xlabel("Product Name")
plt.ylabel("Count")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

train_data['overall_rating'].value_counts().plot(kind='bar', color='red')
plt.title("Distribution of Overall Ratings")
plt.xlabel("Rating")
plt.ylabel("Count")
plt.show()

import spacy
from spacy.lang.en.stop_words import STOP_WORDS
nlp = spacy.load("en_core_web_sm")
def clean_and_extract_tags(text):
    if isinstance(text, str):
        doc = nlp(text.lower())
        tags = [token.text for token in doc if token.text.isalnum() and token.text not in STOP_WORDS]
        return ', '.join(tags)
    return
columns_to_extract_tags_from = ['product_category_tree', 'brand', 'description']

for column in columns_to_extract_tags_from:
    train_data[column] = train_data[column].apply(clean_and_extract_tags)

train_data['Tags'] = train_data[columns_to_extract_tags_from].apply(lambda row: ', '.join(row), axis=1)

train_data

# Step 4: Rating Based Recommendation System
average_ratings = (
    train_data.groupby(['product_name', 'brand', 'image'])['overall_rating']
    .mean()
    .reset_index()
)

# Sort by rating in descending order
top_rated_items = average_ratings.sort_values(by='overall_rating', ascending=False)

# Pick top 10 rated products
rating_base_recommendation = top_rated_items.head(10)

print("â­ Rating Based Recommendation System: (Trending Products) â­")
display(rating_base_recommendation[['product_name', 'brand', 'image', 'overall_rating']])

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity  # you can replace this later if you prefer

def content_based_recommendations(train_data, product_name, top_n=10):
    # Check if the product exists in the dataset
    if product_name not in train_data['product_name'].values:
        print(f"Product '{product_name}' not found in the dataset.")
        return pd.DataFrame()

    # Create a TF-IDF vectorizer for product tags/descriptions
    tfidf_vectorizer = TfidfVectorizer(stop_words='english')

    # Apply TF-IDF on the Tags column (created earlier from Category + Brand + Description)
    tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['Tags'])

    # Compute similarity between products
    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)

    # Find the index of the selected product
    product_index = train_data[train_data['product_name'] == product_name].index[0]

    # Get similarity scores for all products with respect to the selected one
    similarity_scores = list(enumerate(similarity_matrix[product_index]))

    # Sort by similarity score in descending order
    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)

    # Get top N most similar items (excluding the item itself)
    top_items = similarity_scores[1:top_n + 1]

    # Get indices of the top similar products
    recommended_indices = [i[0] for i in top_items]

    # Return details of recommended products
    recommended_products = train_data.iloc[recommended_indices][[
        'product_name', 'brand', 'product_category_tree', 'retail_price',
        'discounted_price', 'image', 'overall_rating'
    ]]

    return recommended_products

#EXAMPLE
# Example: Recommend products similar to a given product
recommendations = content_based_recommendations(train_data, 'Ladela Bellies', top_n=10)
display(recommendations)

# So this step ensures we can build a user-item matrix.
train_data['user_id'] = np.random.randint(1, 501, train_data.shape[0])  # 500 random users

# Step 2: Create a Userâ€“Item matrix
user_item_matrix = (
    train_data.pivot_table(index='user_id', columns='uniq_id', values='overall_rating', aggfunc='mean')
    .fillna(0)
)

# Step 3: Compute user similarity
user_similarity = cosine_similarity(user_item_matrix)

# Step 4: Pick a target user (for example, user_id = 4)
target_user_id = 4

if target_user_id not in user_item_matrix.index:
    print(f"User {target_user_id} not found in dataset â€” try another ID.")
else:
    target_user_index = user_item_matrix.index.get_loc(target_user_id)
    user_similarities = user_similarity[target_user_index]

    # Step 5: Get similar users
    similar_user_indices = user_similarities.argsort()[::-1][1:]  # excluding self

    # Step 6: Recommend items not rated by target user
    recommend_items = []
    for user_index in similar_user_indices:
        rated_by_similar_user = user_item_matrix.iloc[user_index]
        not_rated_by_target_user = (rated_by_similar_user > 0) & (user_item_matrix.iloc[target_user_index] == 0)
        recommend_items.extend(user_item_matrix.columns[not_rated_by_target_user][:10])

    # Step 7: Get details of recommended products
    recommended_items_details = train_data[train_data['uniq_id'].isin(recommend_items)][[
        'product_name', 'brand', 'product_category_tree', 'discounted_price', 'overall_rating', 'image'
    ]]

    # Step 8: Display results
    print("ðŸŽ¯ Recommended Products for User", target_user_id)
    display(recommended_items_details.head(10))

def collaborative_filtering_recommendations(train_data, target_user_id, top_n=10):
    # Step 1: Create a simulated user_id column if not present
    if 'user_id' not in train_data.columns:
        train_data['user_id'] = np.random.randint(1, 501, train_data.shape[0])  # 500 random users

    # Step 2: Create the Userâ€“Item matrix
    user_item_matrix = train_data.pivot_table(
        index='user_id',
        columns='uniq_id',
        values='overall_rating',
        aggfunc='mean'
    ).fillna(0)

    # Step 3: Calculate similarity between users
    user_similarity = cosine_similarity(user_item_matrix)

    # Step 4: Check if the target user exists
    if target_user_id not in user_item_matrix.index:
        print(f"User ID {target_user_id} not found in the dataset.")
        return pd.DataFrame()

    # Step 5: Get index and similarity scores for the target user
    target_user_index = user_item_matrix.index.get_loc(target_user_id)
    user_similarities = user_similarity[target_user_index]

    # Step 6: Sort similar users (excluding the target user)
    similar_users_indices = user_similarities.argsort()[::-1][1:]

    # Step 7: Generate recommendations
    recommended_items = []
    for user_index in similar_users_indices:
        rated_by_similar_user = user_item_matrix.iloc[user_index]
        not_rated_by_target_user = (rated_by_similar_user > 0) & (user_item_matrix.iloc[target_user_index] == 0)
        recommended_items.extend(user_item_matrix.columns[not_rated_by_target_user][:top_n])

    # Step 8: Get product details
    recommended_items_details = train_data[
        train_data['uniq_id'].isin(recommended_items)
    ][['product_name', 'brand', 'product_category_tree', 'discounted_price', 'overall_rating', 'image']]

    return recommended_items_details.head(top_n)

# Example usage
target_user_id = 4
top_n = 5
collaborative_filtering_rec = collaborative_filtering_recommendations(train_data, target_user_id, top_n)

print(f"Top {top_n} Recommendations for User {target_user_id}:")
display(collaborative_filtering_rec)